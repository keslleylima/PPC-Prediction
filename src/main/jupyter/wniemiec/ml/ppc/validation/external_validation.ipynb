{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %run ../util/MathUtils.ipynb\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExternalValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExternalValidation:\n",
    "    def __init__(self, dataset_internal_validation, dataset_external_validation, k=10):\n",
    "        self.__dataset_internal_validation = dataset_internal_validation.get_dataframe()\n",
    "        self.__dataset_external_validation = dataset_external_validation.get_dataframe()\n",
    "        self.__k = k\n",
    "        self.__ppc = self.__dataset_external_validation['PrimePathCoverage'].values\n",
    "        self.__predict_error_table_scaled = None\n",
    "        self.__predict_error_table_noscaled = None\n",
    "        self.__mean_error_scaled_table = None\n",
    "        self.__mean_error_noscaled_table = None\n",
    "        self.__error_metrics_table = pd.DataFrame(\n",
    "            index=['Mean Abs Error', 'Mean Sqr Error', 'Mean Sqr Log Error', 'Mean Median Error', 'R2 Score'],\n",
    "            columns=['no_scaled', 'scaled']\n",
    "        )\n",
    "        self.__full_error_metrics_table_scaled = None\n",
    "        self.__full_error_metrics_table_noscaled = None\n",
    "\n",
    "    def __scale(self, data):\n",
    "        scaler = MinMaxScaler()\n",
    "        return scaler.fit_transform(data)\n",
    "    \n",
    "    def evaluate(self, metrics):\n",
    "        self.__evaluate_scaled(metrics)\n",
    "        self.__evaluate_noscaled(metrics)\n",
    "        self.display_mean_error_table_scaled()\n",
    "        self.display_mean_error_table_noscaled()\n",
    "        \n",
    "    def __evaluate_scaled(self, independent_variables):\n",
    "        independent_variables_values = self.__scale(self.__dataset_external_validation[independent_variables].values)\n",
    "        estimator_metrics_scaled = self.__get_cross_validate_estimator_scaled(independent_variables)\n",
    "        self.__predict_error_table_scaled = self.__build_predict_error_table(estimator_metrics_scaled, independent_variables_values, 'scaled')\n",
    "\n",
    "    def __evaluate_noscaled(self, independent_variables):\n",
    "        independent_variables_values = self.__dataset_external_validation[independent_variables].values\n",
    "        estimator_metrics_noscaled = self.__get_cross_validate_estimator_noscaled(independent_variables)\n",
    "        self.__predict_error_table_noscaled = self.__build_predict_error_table(estimator_metrics_noscaled, independent_variables_values, 'no_scaled')\n",
    "    \n",
    "    def __build_predict_error_table(self, estimator, previsores_content, label):\n",
    "        error_metrics_table = pd.DataFrame(\n",
    "            columns=[0],\n",
    "            index=['Mean Abs Error', 'Mean Sqr Error', 'Mean Sqr Log Error', 'Mean Median Error', 'R2 Score']\n",
    "        )\n",
    "        cyclomatic = self.__dataset_external_validation['Cyclomatic'].values\n",
    "        ec = self.__dataset_external_validation['EdgeCoverage'].values\n",
    "        best_mae = 1\n",
    "        best_predict_table = None\n",
    "        ppc_predict = estimator.predict(previsores_content)\n",
    "        predict_table = pd.DataFrame(index=[i for i in range(len(ppc_predict))],columns=['Cyclomatic', 'EC correct', 'PPC correct', 'PPC predict', 'Error'])\n",
    "\n",
    "        for i in range(len(ppc_predict)):\n",
    "            current_ppc_correct = self.__ppc[i]\n",
    "            current_ppc_predict = MathUtils.truncate(ppc_predict[i], 3)\n",
    "\n",
    "            predict_table.loc[i, 'PPC correct'] = current_ppc_correct\n",
    "            predict_table.loc[i, 'PPC predict'] = current_ppc_predict\n",
    "            predict_table.loc[i, 'EC correct'] = ec[i]\n",
    "            predict_table.loc[i, 'Cyclomatic'] = cyclomatic[i]\n",
    "            predict_table.loc[i, 'Error'] = abs(current_ppc_correct - current_ppc_predict)\n",
    "\n",
    "        error_metrics_table[0]['Mean Abs Error'] = mean_absolute_error(predict_table['PPC correct'].values, predict_table['PPC predict'].values)\n",
    "        error_metrics_table[0]['Mean Sqr Error'] = mean_squared_error(predict_table['PPC correct'].values, predict_table['PPC predict'].values)\n",
    "        error_metrics_table[0]['Mean Sqr Log Error'] = mean_squared_log_error(predict_table['PPC correct'].values, predict_table['PPC predict'].values)\n",
    "        error_metrics_table[0]['Mean Median Error'] = median_absolute_error(predict_table['PPC correct'].values, predict_table['PPC predict'].values)\n",
    "        error_metrics_table[0]['R2 Score'] = r2_score(predict_table['PPC correct'].values, predict_table['PPC predict'].values)\n",
    "        \n",
    "        predict_table.sort_values(by='Error', ascending=False, inplace=True)\n",
    "        \n",
    "        if label == 'scaled':\n",
    "            self.__full_error_metrics_table_scaled = predict_table.copy()\n",
    "        elif label == 'no_scaled':\n",
    "            self.__full_error_metrics_table_noscaled = predict_table.copy()\n",
    "        \n",
    "        return error_metrics_table\n",
    "    \n",
    "    \n",
    "    def __build_full_predict_error_table(self, estimators, previsores_content):\n",
    "        predict_table = pd.DataFrame(columns=['Cyclomatic', 'EC correct', 'PPC predict', 'PPC correct', 'Error'])\n",
    "        cyclomatic = self.__dataset_external_validation['Cyclomatic'].values\n",
    "        ec = self.__dataset_external_validation['EdgeCoverage'].values\n",
    "\n",
    "        for estimator in estimators:\n",
    "            ppc_predict = estimator.predict(previsores_content)\n",
    "            tot_ppc_predict = len(ppc_predict)\n",
    "            current_predict_table = pd.DataFrame(\n",
    "                columns=['Cyclomatic', 'EC correct', 'PPC predict', 'PPC correct', 'Error'],\n",
    "                index=[i for i in range(tot_ppc_predict)]\n",
    "            )\n",
    "\n",
    "            for i in range(tot_ppc_predict):\n",
    "                current_predict_table.loc[i, 'PPC correct'] = self.__ppc[i]\n",
    "                current_predict_table.loc[i, 'PPC predict'] = MathUtils.truncate(ppc_predict[i], 3)\n",
    "                current_predict_table.loc[i, 'EC correct'] = ec[i]\n",
    "                current_predict_table.loc[i, 'Cyclomatic'] = cyclomatic[i]\n",
    "                current_predict_table.loc[i, 'Error'] = abs(self.__ppc[i] - ppc_predict[i])\n",
    "\n",
    "            current_predict_error = current_predict_table['Error'].mean()\n",
    "            best_predict_error = predict_table['Error'].mean()\n",
    "\n",
    "            if (np.isnan(best_predict_error)) or (current_predict_error < best_predict_error):\n",
    "                predict_table = current_predict_table.copy()\n",
    "\n",
    "        predict_table.sort_values(by='Error', ascending=False, inplace=True)\n",
    "\n",
    "        return predict_table\n",
    "    \n",
    "    def __build_mean_error_table(self, predict_table):\n",
    "        error_table = pd.DataFrame(\n",
    "                index=[0], \n",
    "                columns=['Mean Abs Error', 'Mean Sqr Error', 'Mean Sqr Log Error', 'Mean Median Error', 'R2 Score']\n",
    "        )\n",
    "        error_table['Mean Abs Error'] = predict_table['Mean Abs Error'].mean()\n",
    "        error_table['Mean Sqr Error'] = predict_table['Mean Sqr Error'].mean()\n",
    "        error_table['Mean Sqr Log Error'] = predict_table['Mean Sqr Log Error'].mean()\n",
    "        error_table['Mean Median Error'] = predict_table['Mean Median Error'].mean()\n",
    "        error_table['R2 Score'] = predict_table['R2 Score'].mean()\n",
    "        \n",
    "        return error_table\n",
    "\n",
    "    def __get_cross_validate_estimator_scaled(self, previsores):\n",
    "        d = self.__dataset_internal_validation\n",
    "        ppc = d['PrimePathCoverage'].values\n",
    "        previsores_content = d[previsores].values\n",
    "\n",
    "        resultados_escalonados = cross_validate(\n",
    "                RandomForestRegressor(random_state=0), \n",
    "                self.__scale(previsores_content), \n",
    "                ppc, \n",
    "                cv=self.__k,\n",
    "                scoring=['neg_root_mean_squared_error'],\n",
    "                return_estimator=True\n",
    "        )\n",
    "        idx_best_estimator = resultados_escalonados['test_neg_root_mean_squared_error'].argmax()\n",
    "\n",
    "        return resultados_escalonados['estimator'][idx_best_estimator]\n",
    "\n",
    "    def __get_cross_validate_estimator_noscaled(self, previsores):\n",
    "        d = self.__dataset_internal_validation\n",
    "        classificador = RandomForestRegressor(random_state=0)\n",
    "        ppc = d['PrimePathCoverage'].values\n",
    "        previsores_content = d[previsores].values\n",
    "\n",
    "        resultados = cross_validate(\n",
    "                classificador, \n",
    "                previsores_content, \n",
    "                ppc, \n",
    "                cv=self.__k,\n",
    "                scoring=['neg_root_mean_squared_error'],\n",
    "                return_estimator=True\n",
    "        )\n",
    "        idx_best_estimator = resultados['test_neg_root_mean_squared_error'].argmax()\n",
    "\n",
    "        return resultados['estimator'][idx_best_estimator]\n",
    "    \n",
    "    def display_mean_error_table_scaled(self):\n",
    "        self.__display_dataframe_using_title(self.__predict_error_table_scaled, 'With scaling')\n",
    "        self.__display_error_mean_table(self.__full_error_metrics_table_scaled, 'With scaling')\n",
    "        self.__display_interval_error_table(self.__full_error_metrics_table_scaled, 'With scaling')\n",
    "        \n",
    "    def __display_dataframe_using_title(self, dataframe, title):\n",
    "        styled_dataframe = dataframe.style.set_caption(title).set_table_styles([{\n",
    "            'selector': 'caption',\n",
    "            'props': [\n",
    "                ('color', 'black'),\n",
    "                ('font-size', '16px')\n",
    "            ]\n",
    "        }])\n",
    "        display(styled_dataframe)\n",
    "        \n",
    "    def display_mean_error_table_noscaled(self):\n",
    "        self.__display_dataframe_using_title(self.__predict_error_table_noscaled, 'Without scaling')\n",
    "        self.__display_error_mean_table(self.__full_error_metrics_table_noscaled, 'Without scaling')\n",
    "        self.__display_interval_error_table(self.__full_error_metrics_table_noscaled, 'Without scaling')\n",
    "        \n",
    "    def __display_error_mean_table(self, dataset, title):\n",
    "        error_mean_table = pd.DataFrame(\n",
    "            columns=['Cyclomatic', 'Average error', 'Total'],\n",
    "            index=[i for i in range(5)]\n",
    "        )\n",
    "        error_mean_table['Cyclomatic'][0] = '[0;2]'\n",
    "        error_mean_table['Cyclomatic'][1] = '[3;5]'\n",
    "        error_mean_table['Cyclomatic'][2] = '[6;8]'\n",
    "        error_mean_table['Cyclomatic'][3] = '[8;10]'\n",
    "        error_mean_table['Cyclomatic'][4] = '> 10'\n",
    "\n",
    "        error_mean_table['Average error'][0] = dataset[(dataset['Cyclomatic'] >= 0) & (dataset['Cyclomatic'] <= 2)]['Error'].mean()\n",
    "        error_mean_table['Average error'][1] = dataset[(dataset['Cyclomatic'] >= 3) & (dataset['Cyclomatic'] <= 5)]['Error'].mean()\n",
    "        error_mean_table['Average error'][2] = dataset[(dataset['Cyclomatic'] >= 6) & (dataset['Cyclomatic'] <= 8)]['Error'].mean()\n",
    "        error_mean_table['Average error'][3] = dataset[(dataset['Cyclomatic'] >= 8) & (dataset['Cyclomatic'] <= 10)]['Error'].mean()\n",
    "        error_mean_table['Average error'][4] = dataset[dataset['Cyclomatic'] > 10]['Error'].mean()\n",
    "\n",
    "        error_mean_table['Total'][0] = dataset[(dataset['Cyclomatic'] >= 0) & (dataset['Cyclomatic'] <= 2)]['Error'].shape[0]\n",
    "        error_mean_table['Total'][1] = dataset[(dataset['Cyclomatic'] >= 3) & (dataset['Cyclomatic'] <= 5)]['Error'].shape[0]\n",
    "        error_mean_table['Total'][2] = dataset[(dataset['Cyclomatic'] >= 6) & (dataset['Cyclomatic'] <= 8)]['Error'].shape[0]\n",
    "        error_mean_table['Total'][3] = dataset[(dataset['Cyclomatic'] >= 8) & (dataset['Cyclomatic'] <= 10)]['Error'].shape[0]\n",
    "        error_mean_table['Total'][4] = dataset[dataset['Cyclomatic'] > 10]['Error'].shape[0]\n",
    "\n",
    "        self.__display_dataframe_using_title(error_mean_table, title)\n",
    "        \n",
    "    def __display_interval_error_table(self, dataset, title):\n",
    "        MAX_ROWS = 50\n",
    "        pd.set_option('display.max_rows', MAX_ROWS)\n",
    "        error_table = pd.DataFrame(columns=['Interval', 'Total'], index=[0, 1, 2, 3, 4])\n",
    "        \n",
    "        error_table['Interval'][0] = 'Error == 0'\n",
    "        error_table['Total'][0] = dataset[dataset['Error'] == 0].shape[0]\n",
    "        \n",
    "        error_table['Interval'][1] = '0 < Error < 0.3'\n",
    "        error_table['Total'][1] = dataset[(dataset['Error'] > 0) & (dataset['Error'] < 0.3)].shape[0]\n",
    "        \n",
    "        error_table['Interval'][2] = '0.3 <= Error < 0.5'\n",
    "        error_table['Total'][2] = dataset[(dataset['Error'] >= 0.3) & (dataset['Error'] < 0.5)].shape[0]\n",
    "        \n",
    "        error_table['Interval'][3] = '0.5 <= Error < 0.7'\n",
    "        error_table['Total'][3] = dataset[(dataset['Error'] >= 0.5) & (dataset['Error'] < 0.7)].shape[0]\n",
    "        \n",
    "        error_table['Interval'][4] = 'Error >= 0.7'\n",
    "        error_table['Total'][4] = dataset[dataset['Error'] >= 0.7].shape[0]\n",
    "        \n",
    "        self.__display_dataframe_using_title(error_table, title)\n",
    "        self.__display_dataframe_using_title(dataset.iloc[0:MAX_ROWS, :], title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
